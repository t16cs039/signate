{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"last.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1H2Hgw-u7aEvRHRrKakRLe2koloDN_Z0e","authorship_tag":"ABX9TyMo+sF/JpY88U/e6KpSYLjT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"q1JnxllDHyKh"},"source":["# loading packages"]},{"cell_type":"code","metadata":{"id":"H8NHEUDCH12f"},"source":["import pandas as pd\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","import numpy as np\n","from keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-l9C6e8pH4Ve"},"source":["# static"]},{"cell_type":"code","metadata":{"id":"6BZByFHc59n0"},"source":["TRAIN_PATH = '/content/drive/MyDrive/student_cup_2021/dataset/train.csv'\n","TEST_PATH = '/content/drive/MyDrive/student_cup_2021/dataset/test.csv'\n","\n","MODEL_PATH = 'model.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gH4M0t3NH6Dv"},"source":["# loading data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDRLrDbQ606H","executionInfo":{"status":"ok","timestamp":1620449681431,"user_tz":-540,"elapsed":1110,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"fc07b967-ac71-49ac-ab2d-3b45e6765c74"},"source":["df_train = pd.read_csv(TRAIN_PATH)\n","df_test = pd.read_csv(TEST_PATH)\n","\n","print('df_train shape: {0}, df_test shape: {1}'.format(df_train.shape, df_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["df_train shape: (4046, 14), df_test shape: (4046, 13)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3t1eHdsyH8Qo"},"source":["# hand-labeling"]},{"cell_type":"code","metadata":{"id":"-NmZ5j7_7sxB"},"source":["'''\n","# How to checked it... #\n","col = categorical feature\n","'''\n","# df_train.groupby(\"col\")[\"target\"].value_counts()\n","\n","''' \n","# Hand-Labeling # \n","if popularity == 2: genre = 10\n","if popularity == 82: genre = 0\n","if tempo == '41-52': genre = 1\n","if region == 'region_M': genre = 7\n","if popularity == 5: genre = 10\n","'''\n","df_test['genre'] = -100\n","\n","df_test.loc[df_test['popularity'] == 2, 'genre'] = 10\n","df_test.loc[df_test['popularity'] == 82, 'genre'] = 0\n","df_test.loc[df_test['tempo'] == '41-52', 'genre'] = 1\n","df_test.loc[df_test['region'] == 'region_M', 'genre'] = 7\n","df_test.loc[df_test['popularity'] == 5, 'genre'] = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qfddC4cxQsqb"},"source":["# preparing data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72GGdracQsws","executionInfo":{"status":"ok","timestamp":1620449681432,"user_tz":-540,"elapsed":1098,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"7d8b65cf-931e-4849-cfaa-e086a4dfc574"},"source":["df = pd.concat([df_train, df_test], axis=0)\n","df = df.drop(['index'], axis=1)\n","\n","print('df shape: {0}'.format(df.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["df shape: (8092, 13)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oPnO00LAKfjm"},"source":["# preprocessing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cHjjBZSfLWeK","executionInfo":{"status":"ok","timestamp":1620449681432,"user_tz":-540,"elapsed":1093,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"5137c93b-f52c-4a8e-c24c-18cc321e5764"},"source":["'''\n","# missing value #\n","fill in the avg of the data\n","'''\n","df = df.fillna(df.mean())\n","\n","'''\n","# popularity #\n","min-max scaling\n","'''\n","df['popularity'] = (df['popularity'] - df['popularity'].min()) / (df['popularity'].max() - df['popularity'].min())\n","\n","'''\n","# duration_ms #\n","[min, max]\n","[5826, 2135773] -> [3.765, 6.33] (log scaling) -> [0, 1] (min-max scaling)\n","'''\n","df['duration_ms'] = np.log(df['duration_ms'])\n","df['duration_ms'] = (df['duration_ms'] - df['duration_ms'].min()) - (df['duration_ms'].max() - df['duration_ms'].min())\n","\n","'''\n","# loudness #\n","[min, max]\n","[0, -37.82] -> [0, 1] (napier to the - power)\n","'''\n","df['loudness'] = np.e**df['loudness']\n","\n","'''\n","# tempo #\n","one-hot encoding\n","'''\n","df = pd.concat([df, pd.get_dummies(df['tempo'])], axis=1)\n","df = df.drop(['tempo'], axis=1)\n","\n","'''\n","# region #\n","one-hot encoding\n","'''\n","df = pd.concat([df, pd.get_dummies(df['region'])], axis=1)\n","df = df.drop(['region'], axis=1)\n","\n","print('df shape: {0}'.format(df.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["df shape: (8092, 44)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mxuRJRqhKfy1"},"source":["# creating data for training "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a1Z93pBKf4l","executionInfo":{"status":"ok","timestamp":1620451464394,"user_tz":-540,"elapsed":525,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"4ae88383-1064-4256-d497-1ced987affaa"},"source":["train_data = df[df['genre'] != -100]\n","\n","X_train = train_data.drop(['genre'], axis=1).values\n","cY_train = to_categorical(train_data['genre'])\n","X_test = df.drop(['genre'], axis=1).iloc[4046:, :].values\n","\n","print('train data shape: {0}, X_train shape: {1}, cY_train shape: {2}'.format(train_data.shape, X_train.shape, cY_train.shape))\n","print('X_test shape: {0}'.format(X_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train data shape: (4076, 44), X_train shape: (4076, 43), cY_train shape: (4076, 11)\n","X_test shape: (4046, 43)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dzxT834IUIxs"},"source":["# creating model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QlGtuBaQUI4u","executionInfo":{"status":"ok","timestamp":1620449684278,"user_tz":-540,"elapsed":3926,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"1239a7be-7f6b-4e90-f7cf-1fdaec88a945"},"source":["!pip install tensorflow_addons\n","import tensorflow_addons as tfa\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, BatchNormalization, LeakyReLU\n","from keras.optimizers import Adam\n","\n","def create_model():\n","\n","  model = Sequential()\n","\n","  model.add(Dense(100, input_shape=(X_train.shape[1],)))\n","  model.add(BatchNormalization())\n","  model.add(LeakyReLU(alpha=0.01))\n","\n","  model.add(Dense(50))\n","  model.add(BatchNormalization())\n","  model.add(LeakyReLU(alpha=0.01))\n","  \n","  model.add(Dense(cY_train.shape[1], activation='softmax'))\n"," \n","  model.compile(optimizer=Adam(lr=1e-3),\n","                loss = tfa.losses.SigmoidFocalCrossEntropy(),\n","                metrics=['accuracy'],)\n","  \n","  return model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h75qxmUJKf_K"},"source":["# cv for ensemble"]},{"cell_type":"code","metadata":{"id":"J_tlgQW5U0V8"},"source":["from keras.callbacks import Callback\n","from sklearn.metrics import f1_score\n","import numpy as np\n","\n","class CustomCallback(Callback):\n","\n","  def __init__(self, model, x_val, cy_val, model_path):\n","    self.model = model\n","    self.x_val = x_val\n","    self.cy_val = cy_val\n","    self.model_path = model_path\n","    self.max = 0\n","  \n","  def on_epoch_end(self, epoch, logs=None):\n","    score = f1_score(np.argmax(self.cy_val, axis=1), np.argmax(self.model.predict(self.x_val), axis=1), average='macro')\n","    if self.max < score:\n","      self.max = score\n","      self.model.save(self.model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mepES7B6UMfl"},"source":["from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","from sklearn.metrics import f1_score\n","\n","def cross_val_score_for_ensemble(X_train, Y_train, epochs, batch_size, n_splits=10):\n","\n","  skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2021)\n","\n","  loss=[]\n","  acc=[]\n","  f1_macro = []\n","  model_list = []\n","\n","  num = 0\n","\n","  for train_idx, val_idx in skf.split(X_train, cY_train.argmax(axis=1)):\n","    train_data = X_train[train_idx]\n","    train_labels = cY_train[train_idx]\n","    val_data = X_train[val_idx]\n","    val_labels = cY_train[val_idx]\n","\n","    model = create_model()\n","    model_path = str(num)+'_'+MODEL_PATH\n","    callbacks_list = [CustomCallback(model, val_data, val_labels, model_path),]\n","    history = model.fit(train_data, train_labels, \n","                        epochs=epochs, \n","                        batch_size=batch_size, \n","                        callbacks=callbacks_list, \n","                        verbose=0, \n","                        validation_data=(val_data, val_labels))\n","    model_list.append(load_model(model_path))\n","\n","    score = f1_score(np.argmax(val_labels, axis=1), np.argmax(model_list[num].predict(val_data), axis=1), average='macro')\n","    f1_macro.append(score)\n","    print('f1 macro: {0:.3f}'.format(score))\n","\n","    num += 1\n","\n","  return f1_macro, model_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCCOkJVhKgFf","executionInfo":{"status":"ok","timestamp":1620451331009,"user_tz":-540,"elapsed":1650642,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"d987239f-66f2-4034-eabd-d977cc5f54f9"},"source":["from time import time\n","\n","EPOCHS = 500\n","BATCH_SIZE = 32\n","\n","start_time = time()\n","f1_macro, model_list = cross_val_score_for_ensemble(X_train, cY_train, EPOCHS, BATCH_SIZE, 10)\n","elapsed_time = time() - start_time\n","\n","print('Elapsed time: {0:.3f} hrs'.format(elapsed_time / 3600))\n","print('f1 macro for cv: {0:.3f}'.format(np.mean(f1_macro)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["f1 macro: 0.645\n","f1 macro: 0.606\n","f1 macro: 0.669\n","f1 macro: 0.598\n","f1 macro: 0.583\n","f1 macro: 0.648\n","f1 macro: 0.541\n","f1 macro: 0.586\n","f1 macro: 0.550\n","f1 macro: 0.603\n","Elapsed time: 0.457 hrs\n","f1 macro for cv: 0.603\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YLA1hE7rKgMQ"},"source":["# submission"]},{"cell_type":"code","metadata":{"id":"-y56P5sYKgSz"},"source":["import numpy as np\n","\n","predicted =  np.argmax(np.mean([model_list[0].predict(X_test),\n","                                model_list[2].predict(X_test),\n","                                model_list[3].predict(X_test),\n","                                model_list[4].predict(X_test),\n","                                model_list[5].predict(X_test),\n","                                model_list[6].predict(X_test),\n","                                model_list[7].predict(X_test),\n","                                model_list[8].predict(X_test),\n","                                model_list[9].predict(X_test),], axis=0), axis=1)\n","\n","df_sub = pd.concat([df_test['index'].reset_index(drop=True), pd.DataFrame(predicted, columns=['predicted']).astype(int)], axis=1)\n","# df_sub.to_csv('submission.csv', index=False, header=False)\n","\n","df_sub.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yTvDBiN2YAzB"},"source":["# import numpy as np\n","\n","# preds = model_list[0].predict(X_test)*f1_macro[0]/np.sum(f1_macro)\n","\n","# for i in range(1, 10):\n","#   preds += model_list[i].predict(X_test)*f1_macro[i]/np.sum(f1_macro)\n","\n","# preds = np.argmax(preds, axis=1)\n","\n","# df_sub = pd.concat([df_test['index'].reset_index(drop=True), pd.DataFrame(preds, columns=['predicted']).astype(int)], axis=1)\n","\n","# df_sub.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stFD-WVihPQG"},"source":["# for ge, ind in zip(df_test[df_test['genre'] != -100]['genre'], df_test[df_test['genre'] != -100]['index']):\n","#   df_sub.loc[df_sub['index'] == ind, 'predicted'] = ge\n","\n","# df_sub.to_csv('submission.csv', index=False, header=False)\n","\n","# df_sub.head()"],"execution_count":null,"outputs":[]}]}