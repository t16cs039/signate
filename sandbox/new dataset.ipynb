{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"new dataset.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"15JYmFVPlwLs7ui-MOTeoZC5N3O-vjVG6","authorship_tag":"ABX9TyMn67mBQ0OfAa084aH5yoJI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UKcwkVO03dS4"},"source":["# pip"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kUN2tuws3ha4","executionInfo":{"status":"ok","timestamp":1614681578296,"user_tz":-540,"elapsed":3942,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"bd166198-bda3-4e39-b535-bf1031761b9d"},"source":["!pip install tensorflow_addons"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow_addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n","\r\u001b[K     |▌                               | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 12.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 11.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.12.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kFopONopq1rN"},"source":["# Function"]},{"cell_type":"code","metadata":{"id":"A5fdZpaipegU","executionInfo":{"status":"ok","timestamp":1614681578305,"user_tz":-540,"elapsed":3948,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}}},"source":["### F1 score for metrics ###\r\n","# import keras.backend as K\r\n","\r\n","# def f1_score(y_true, y_pred):\r\n","#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n","#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n","#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n","#     precision = true_positives / (predicted_positives + K.epsilon())\r\n","#     recall = true_positives / (possible_positives + K.epsilon())\r\n","#     f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\r\n","#     return f1_val\r\n","\r\n","\r\n","\r\n","### learning rate schedule ###\r\n","# def exponetial_decay(lr0, s):\r\n","#   def exponetial_decay_fn(epoch):\r\n","#     return lr0 * 0.1 ** (epoch / s)\r\n","#   return exponetial_decay_fn\r\n","\r\n","\r\n","### F1 score for callback ###\r\n","# from sklearn.metrics import f1_score\r\n","# from keras.callbacks import Callback\r\n","\r\n","# class F1Callback(Callback):\r\n","  \r\n","#   def __init__(self, model, x_val, y_val):\r\n","#     self.model = model\r\n","#     self.x_val = x_val\r\n","#     self.y_val = y_val\r\n","\r\n","#   def on_epoch_end(self, epoch, logs):\r\n","#     pred = self.model.predict(self.x_val)\r\n","#     f1 = f1_score(self.y_val, np.round(pred))\r\n","#     print('f1_val: {0}'.format(f1))"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uysHH-rLq3Y-"},"source":["# Static"]},{"cell_type":"code","metadata":{"id":"TFzGUc1nrQ8q","executionInfo":{"status":"ok","timestamp":1614681578306,"user_tz":-540,"elapsed":3946,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}}},"source":["TRAIN_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/train_images.csv'\r\n","TEST_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/test_images.csv'\r\n","SAMPLE_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/sample_submit.csv'\r\n","\r\n","TRAIN_IMAGE_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/train_images'\r\n","TEST_IMAGE_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/test_images'\r\n","\r\n","MODEL_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/model.h5'\r\n","\r\n","TRAIN_TEST_SPLIT = 0.2\r\n","IMAGE_SIZE = 640\r\n","BATCH_SIZE = 4\r\n","EPOCHS = 100\r\n","\r\n","# CONV_DROPOUT_RATE = 0.2"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vb88HG0Iq3bM"},"source":["# Import data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Sii-MJ5rRXg","executionInfo":{"status":"ok","timestamp":1614681579756,"user_tz":-540,"elapsed":5393,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"e01665da-6547-40aa-843a-68c54d110dd3"},"source":["import pandas as pd\r\n","pd.set_option('display.max_colwidth', 100)\r\n","\r\n","df = pd.read_csv(TRAIN_PATH)\r\n","df_test = pd.read_csv(TEST_PATH)\r\n","\r\n","df['id'] = TRAIN_IMAGE_PATH+'/'+df['id']\r\n","\r\n","df['class_num'] = df['class_num'].astype(str)\r\n","\r\n","print('df shape: {0}, df_test shape: {1}'.format(df.shape, df_test.shape))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["df shape: (1102, 2), df_test shape: (1651, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eP9M6rJuq3ff"},"source":["# ImageDataGenerator"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uVpAuiPZrR7b","executionInfo":{"status":"ok","timestamp":1614681588532,"user_tz":-540,"elapsed":14161,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"beb2051a-3423-453f-c0bb-d862d2d844a6"},"source":["from sklearn.model_selection import train_test_split\r\n","\r\n","df_train, df_val = train_test_split(df, test_size=TRAIN_TEST_SPLIT, random_state=2021)\r\n","\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","\r\n","train_datagen = ImageDataGenerator(featurewise_center=False,\r\n","                                   samplewise_center=False,\r\n","                                   featurewise_std_normalization=False,\r\n","                                   samplewise_std_normalization=False,\r\n","                                   zca_whitening=False,\r\n","                                   rotation_range=180,\r\n","                                   width_shift_range=1.0,\r\n","                                   height_shift_range=1.0,\r\n","                                   shear_range=0.2,\r\n","                                   zoom_range=0.2,\r\n","                                   channel_shift_range=0.0,\r\n","                                   fill_mode='nearest',\r\n","                                   cval=0.0,\r\n","                                   horizontal_flip=True,\r\n","                                   vertical_flip=True,\r\n","                                   rescale=1./255.,\r\n","                                   preprocessing_function=None,\r\n","                                   data_format=None,)\r\n","# train_datagen = ImageDataGenerator(rescale=1./255.)\r\n","val_datagen = ImageDataGenerator(rescale=1./255.)\r\n","\r\n","train_generator = train_datagen.flow_from_dataframe(df_train, directory=TRAIN_IMAGE_PATH, x_col='id', y_col='class_num', target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, class_mode='categorical')\r\n","val_generator = val_datagen.flow_from_dataframe(df_val, directory=TRAIN_IMAGE_PATH, x_col='id', y_col='class_num', target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, class_mode='categorical')\r\n","# train_generator = train_datagen.flow_from_dataframe(df, directory=TRAIN_IMAGE_PATH, x_col='id', y_col='class_num', target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, class_mode='sparse')\r\n","\r\n","for data_batch, labels_batch in train_generator:\r\n","  print('data batch shape: ', data_batch.shape)\r\n","  print('labels batch shape: ', labels_batch.shape)\r\n","  break"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Found 881 validated image filenames belonging to 4 classes.\n","Found 221 validated image filenames belonging to 4 classes.\n","data batch shape:  (4, 640, 640, 3)\n","labels batch shape:  (4, 4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TbW4M29_q3h8"},"source":["# Fine tuning"]},{"cell_type":"code","metadata":{"id":"YQtGXrs1rSe8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614681594910,"user_tz":-540,"elapsed":20537,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"0880aa83-ad85-4a6a-df08-7ab863bccc59"},"source":["from keras import models\r\n","from tensorflow.keras.applications import EfficientNetB0, EfficientNetB5, VGG16, ResNet50\r\n","from keras.layers import Conv2D, Activation, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense, Flatten\r\n","\r\n","model = models.Sequential()\r\n","\r\n","conv_base = VGG16(weights='imagenet', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False)\r\n","# conv_base = ResNet50(weights='imagenet', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False)\r\n","# conv_base = EfficientNetB5(weights='imagenet', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False)\r\n","\r\n","### VGG16 ###\r\n","# TARGET_LAYER = 'blcok4_conv3'\r\n","# TARGET_LAYER = 'block5_conv1'\r\n","# TARGET_LAYER = 'block5_conv2'\r\n","# TARGET_LAYER = 'block5_conv3'\r\n","### ResNet50 ###\r\n","# TARGET_LAYER = 'conv5_block3_1_conv'\r\n","# TARGET_LAYER = 'conv5_block1_1_conv'\r\n","# TARGET_LAYER = 'conv4_block1_1_conv'\r\n","\r\n","# conv_base.trainable = True\r\n","# set_trainable = False\r\n","\r\n","# for layer in conv_base.layers:\r\n","#   if layer.name == TARGET_LAYER:\r\n","#     set_trainable = True\r\n","#   if set_trainable:\r\n","#     layer.trainable = True\r\n","#   else:\r\n","#     layer.trainable = False\r\n","\r\n","### Transfer learing ###\r\n","for layer in conv_base.layers:\r\n","  layer.trainable = False\r\n","\r\n","model.add(conv_base)\r\n","\r\n","# model.add(Flatten())\r\n","model.add(GlobalAveragePooling2D())\r\n","# model.add(BatchNormalization())\r\n","# model.add(Dense(256, activation='relu'))\r\n","# model.add(BatchNormalization())\r\n","# model.add(Dense(256, activation='relu'))\r\n","# model.add(BatchNormalization())\r\n","# model.add(Dense(256, activation='relu'))\r\n","# model.add(BatchNormalization())\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(2048, activation='relu'))\r\n","model.add(Dropout(0.5))\r\n","# model.add(Dense(1024, activation='relu'))\r\n","# model.add(Dropout(0.5))\r\n","# model.add(Dense(1024, activation='relu'))\r\n","# model.add(Dropout(0.5))\r\n","# model.add(Dense(1024, activation='relu'))\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(4, activation='softmax'))\r\n","\r\n","# conv_base.summary()\r\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 20, 20, 512)       14714688  \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 512)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 512)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 2048)              1050624   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              2098176   \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4)                 4100      \n","=================================================================\n","Total params: 19,966,788\n","Trainable params: 5,252,100\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xu7PKE0DwO-i"},"source":["# Create model\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"Te99kL5xwPEH","executionInfo":{"status":"ok","timestamp":1614681891859,"user_tz":-540,"elapsed":726,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}}},"source":["from keras.optimizers import Adam, SGD\r\n","from tensorflow_addons.losses import WeightedKappaLoss\r\n","from tensorflow_addons.metrics import F1Score, CohenKappa\r\n","\r\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(1e-5), metrics=['accuracy'])\r\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=SGD(lr=1e-5, momentum=0.9, nesterov=True), metrics=['accuracy'])\r\n","# model.compile(loss=WeightedKappaLoss(num_classes=4), optimizer=SGD(lr=1e-5, momentum=0.9, nesterov=True), metrics=['accuracy'])\r\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=SGD(lr=1e-5, momentum=0.9, nesterov=True), metrics=['accuracy', CohenKappa(num_classes=4)])\r\n","# model.compile(loss=WeightedKappaLoss(num_classes=4), optimizer=SGD(lr=1e-5, momentum=0.9, nesterov=True), metrics=['accuracy', F1Score(num_classes=4), CohenKappa(num_classes=4)])\r\n","\r\n","### Transfer learning ###\r\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=SGD(lr=0.2, momentum=0.9, decay=0.01), metrics=['accuracy'])\r\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-2), metrics=['accuracy'])"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oeZKs_Hgq3j8"},"source":["# Make callbacks and Training"]},{"cell_type":"code","metadata":{"id":"bB0-2Fz4rS3c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"650796b9-2bfc-4b66-851f-a2b205cbe671"},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\r\n","import time\r\n","\r\n","MONITOR_EARLYSTOPPING = 'val_loss'\r\n","MONITOR_MODELCHECKPOINT = 'val_loss'\r\n","\r\n","callbacks_list = [EarlyStopping(monitor=MONITOR_EARLYSTOPPING, patience=5, mode='min',),\r\n","                  # LearningRateScheduler(exponetial_decay(lr0=1e-2, s=10)),\r\n","                  ModelCheckpoint(filepath=MODEL_PATH, monitor=MONITOR_MODELCHECKPOINT, save_best_only=True, mode='min',),]\r\n","\r\n","history = model.fit(train_generator, epochs=EPOCHS, callbacks=EarlyStopping(monitor=MONITOR_EARLYSTOPPING, patience=1, mode='min',), validation_data=val_generator)\r\n","\r\n","### Transfer learning ###\r\n","for layer in conv_base.layers:\r\n","  layer.trainable = True\r\n","\r\n","# model.compile(loss='sparse_categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, decay=0.001), metrics=['accuracy'])\r\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-5), metrics=['accuracy'])\r\n","\r\n","start = time.time()\r\n","\r\n","history = model.fit(train_generator, epochs=EPOCHS, callbacks=callbacks_list, validation_data=val_generator)\r\n","\r\n","elapsed_time = time.time() - start\r\n","print('Elapsed time: {:.1f}[min]'.format(elapsed_time / 60))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","221/221 [==============================] - 657s 3s/step - loss: 5.6037 - accuracy: 0.2484 - val_loss: 1.3893 - val_accuracy: 0.3258\n","Epoch 2/100\n","221/221 [==============================] - 85s 386ms/step - loss: 1.3917 - accuracy: 0.3630 - val_loss: 1.3871 - val_accuracy: 0.3258\n","Epoch 3/100\n","221/221 [==============================] - 84s 378ms/step - loss: 1.3553 - accuracy: 0.3662 - val_loss: 1.3768 - val_accuracy: 0.3258\n","Epoch 4/100\n","221/221 [==============================] - 84s 378ms/step - loss: 1.3751 - accuracy: 0.3325 - val_loss: 1.3894 - val_accuracy: 0.3258\n","Epoch 1/100\n","221/221 [==============================] - 102s 454ms/step - loss: 1.3764 - accuracy: 0.3341 - val_loss: 1.3892 - val_accuracy: 0.3258\n","Epoch 2/100\n","221/221 [==============================] - 104s 468ms/step - loss: 1.3618 - accuracy: 0.3569 - val_loss: 1.3890 - val_accuracy: 0.3258\n","Epoch 3/100\n","221/221 [==============================] - 104s 468ms/step - loss: 1.3616 - accuracy: 0.3568 - val_loss: 1.3889 - val_accuracy: 0.3258\n","Epoch 4/100\n","221/221 [==============================] - 103s 464ms/step - loss: 1.3490 - accuracy: 0.3705 - val_loss: 1.3887 - val_accuracy: 0.3258\n","Epoch 5/100\n","221/221 [==============================] - 104s 466ms/step - loss: 1.3481 - accuracy: 0.3872 - val_loss: 1.3886 - val_accuracy: 0.3258\n","Epoch 6/100\n","221/221 [==============================] - 103s 465ms/step - loss: 1.3607 - accuracy: 0.3597 - val_loss: 1.3885 - val_accuracy: 0.3258\n","Epoch 7/100\n","221/221 [==============================] - 102s 462ms/step - loss: 1.3479 - accuracy: 0.3805 - val_loss: 1.3883 - val_accuracy: 0.3258\n","Epoch 8/100\n","221/221 [==============================] - 102s 460ms/step - loss: 1.3736 - accuracy: 0.3688 - val_loss: 1.3881 - val_accuracy: 0.3258\n","Epoch 9/100\n","221/221 [==============================] - 102s 461ms/step - loss: 1.3481 - accuracy: 0.3753 - val_loss: 1.3880 - val_accuracy: 0.3258\n","Epoch 10/100\n","221/221 [==============================] - 101s 458ms/step - loss: 1.3585 - accuracy: 0.3837 - val_loss: 1.3878 - val_accuracy: 0.3258\n","Epoch 11/100\n","221/221 [==============================] - 101s 455ms/step - loss: 1.3568 - accuracy: 0.3627 - val_loss: 1.3877 - val_accuracy: 0.3258\n","Epoch 12/100\n","221/221 [==============================] - 101s 457ms/step - loss: 1.3432 - accuracy: 0.3908 - val_loss: 1.3876 - val_accuracy: 0.3258\n","Epoch 13/100\n","221/221 [==============================] - 101s 456ms/step - loss: 1.3542 - accuracy: 0.3686 - val_loss: 1.3875 - val_accuracy: 0.3258\n","Epoch 14/100\n","221/221 [==============================] - 101s 456ms/step - loss: 1.3607 - accuracy: 0.3483 - val_loss: 1.3874 - val_accuracy: 0.3258\n","Epoch 15/100\n","221/221 [==============================] - 102s 458ms/step - loss: 1.3438 - accuracy: 0.3879 - val_loss: 1.3873 - val_accuracy: 0.3258\n","Epoch 16/100\n","221/221 [==============================] - 101s 456ms/step - loss: 1.3437 - accuracy: 0.3917 - val_loss: 1.3872 - val_accuracy: 0.3258\n","Epoch 17/100\n","221/221 [==============================] - 101s 457ms/step - loss: 1.3476 - accuracy: 0.3812 - val_loss: 1.3870 - val_accuracy: 0.3258\n","Epoch 18/100\n","221/221 [==============================] - 102s 459ms/step - loss: 1.3353 - accuracy: 0.3798 - val_loss: 1.3869 - val_accuracy: 0.3258\n","Epoch 19/100\n","221/221 [==============================] - 102s 460ms/step - loss: 1.3498 - accuracy: 0.3805 - val_loss: 1.3868 - val_accuracy: 0.3258\n","Epoch 20/100\n","221/221 [==============================] - 102s 461ms/step - loss: 1.3583 - accuracy: 0.3475 - val_loss: 1.3867 - val_accuracy: 0.3258\n","Epoch 21/100\n","221/221 [==============================] - 102s 463ms/step - loss: 1.3593 - accuracy: 0.3573 - val_loss: 1.3867 - val_accuracy: 0.3258\n","Epoch 22/100\n","221/221 [==============================] - 102s 459ms/step - loss: 1.3498 - accuracy: 0.3612 - val_loss: 1.3865 - val_accuracy: 0.3258\n","Epoch 23/100\n","221/221 [==============================] - 101s 459ms/step - loss: 1.3392 - accuracy: 0.3810 - val_loss: 1.3865 - val_accuracy: 0.3258\n","Epoch 24/100\n","221/221 [==============================] - 102s 459ms/step - loss: 1.3572 - accuracy: 0.3638 - val_loss: 1.3864 - val_accuracy: 0.3258\n","Epoch 25/100\n","221/221 [==============================] - 101s 455ms/step - loss: 1.3554 - accuracy: 0.3574 - val_loss: 1.3862 - val_accuracy: 0.3258\n","Epoch 26/100\n","221/221 [==============================] - 101s 454ms/step - loss: 1.3497 - accuracy: 0.3796 - val_loss: 1.3862 - val_accuracy: 0.3258\n","Epoch 27/100\n","221/221 [==============================] - 101s 456ms/step - loss: 1.3521 - accuracy: 0.3697 - val_loss: 1.3861 - val_accuracy: 0.3258\n","Epoch 28/100\n","221/221 [==============================] - 101s 455ms/step - loss: 1.3393 - accuracy: 0.3984 - val_loss: 1.3859 - val_accuracy: 0.3258\n","Epoch 29/100\n","221/221 [==============================] - 101s 454ms/step - loss: 1.3529 - accuracy: 0.3682 - val_loss: 1.3858 - val_accuracy: 0.3258\n","Epoch 30/100\n","221/221 [==============================] - 101s 457ms/step - loss: 1.3562 - accuracy: 0.3551 - val_loss: 1.3857 - val_accuracy: 0.3258\n","Epoch 31/100\n","221/221 [==============================] - 101s 454ms/step - loss: 1.3546 - accuracy: 0.3625 - val_loss: 1.3857 - val_accuracy: 0.3258\n","Epoch 32/100\n","221/221 [==============================] - 101s 455ms/step - loss: 1.3295 - accuracy: 0.4017 - val_loss: 1.3856 - val_accuracy: 0.3258\n","Epoch 33/100\n","221/221 [==============================] - 101s 457ms/step - loss: 1.3334 - accuracy: 0.3880 - val_loss: 1.3855 - val_accuracy: 0.3258\n","Epoch 34/100\n","221/221 [==============================] - 102s 461ms/step - loss: 1.3613 - accuracy: 0.3473 - val_loss: 1.3854 - val_accuracy: 0.3258\n","Epoch 35/100\n","221/221 [==============================] - 101s 456ms/step - loss: 1.3474 - accuracy: 0.3890 - val_loss: 1.3854 - val_accuracy: 0.3258\n","Epoch 36/100\n","221/221 [==============================] - 101s 458ms/step - loss: 1.3422 - accuracy: 0.3962 - val_loss: 1.3852 - val_accuracy: 0.3258\n","Epoch 37/100\n","221/221 [==============================] - 101s 456ms/step - loss: 1.3438 - accuracy: 0.3847 - val_loss: 1.3852 - val_accuracy: 0.3258\n","Epoch 38/100\n","221/221 [==============================] - 101s 457ms/step - loss: 1.3365 - accuracy: 0.3822 - val_loss: 1.3851 - val_accuracy: 0.3258\n","Epoch 39/100\n","221/221 [==============================] - 101s 457ms/step - loss: 1.3598 - accuracy: 0.3566 - val_loss: 1.3849 - val_accuracy: 0.3258\n","Epoch 40/100\n","221/221 [==============================] - 101s 457ms/step - loss: 1.3614 - accuracy: 0.3616 - val_loss: 1.3849 - val_accuracy: 0.3258\n","Epoch 41/100\n","221/221 [==============================] - 101s 456ms/step - loss: 1.3587 - accuracy: 0.3567 - val_loss: 1.3848 - val_accuracy: 0.3258\n","Epoch 42/100\n"," 62/221 [=======>......................] - ETA: 1:10 - loss: 1.3538 - accuracy: 0.3637"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7Mol3_N_q3l-"},"source":["# Evaluate"]},{"cell_type":"code","metadata":{"id":"wyHFJlPhrTZ8"},"source":["import matplotlib.pyplot as plt\r\n","\r\n","acc = history.history['accuracy']\r\n","val_acc = history.history['val_accuracy']\r\n","loss = history.history['loss']\r\n","val_loss = history.history['val_loss']\r\n","epochs = range(1, len(acc) + 1)\r\n","\r\n","fig = plt.figure(0)\r\n","\r\n","plt.plot(epochs, acc, 'b', label='Training acc')\r\n","plt.plot(epochs, val_acc, 'b', color='orange', label='Validation acc')\r\n","plt.title('Training and validation accuracy')\r\n","plt.legend()\r\n","\r\n","fig.savefig('acc.jpg')\r\n","\r\n","plt.show()\r\n","\r\n","fig = plt.figure(1)\r\n","\r\n","plt.plot(epochs, loss, 'b', label='Training loss')\r\n","plt.plot(epochs, val_loss, 'b', color='orange', label='Validation loss')\r\n","plt.title('Training and validation loss')\r\n","plt.legend()\r\n","\r\n","fig.savefig('loss.jpg')\r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ghWu1F82q3oM"},"source":["# Submit"]},{"cell_type":"code","metadata":{"id":"VPxboOFArUBM"},"source":["from keras.models import load_model\r\n","import numpy as np\r\n","from PIL import Image\r\n","\r\n","clf = load_model(MODEL_PATH)\r\n","# clf = load_model(MODEL_PATH, custom_objects={'f1_score': f1_score})\r\n","\r\n","preds = []\r\n","\r\n","for image_id in df_test['id']:\r\n","    image = Image.open(TEST_IMAGE_PATH+'/'+image_id)\r\n","    image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\r\n","    image = np.expand_dims(image, axis=0)\r\n","    image = image / 255.\r\n","    preds.append(np.argmax(clf.predict(image)))\r\n","    # preds.append(np.argmax(model.predict(image)))\r\n","\r\n","df_test['label'] = preds\r\n","\r\n","df_test.to_csv('/content/drive/MyDrive/SANDBOX/DATASET/submission.csv', index=False, header=False)\r\n","\r\n","df_test.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-xWFSGXIq3qN"},"source":["# As for Google Colab\r\n","\r\n","```javascript\r\n","function ClickConnect(){ \r\n","console.log(\"Working\"); \r\n","document.querySelector(\"#comments > span\").click()\r\n","}\r\n","setInterval(ClickConnect,500000)\r\n","```"]},{"cell_type":"code","metadata":{"id":"WntRX-xcq2x0","executionInfo":{"status":"aborted","timestamp":1614681604677,"user_tz":-540,"elapsed":30280,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}}},"source":[""],"execution_count":null,"outputs":[]}]}