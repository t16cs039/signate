{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"qwk.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1eCP-JQErCXV8_-Upm9hC-5YJxMEnWCWK","authorship_tag":"ABX9TyMnvAs8A8Z8okv8mYiqjqtC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"c-MYFyPG-ZiH"},"source":["# pip"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwXcqTFe-X7s","executionInfo":{"status":"ok","timestamp":1615341220359,"user_tz":-540,"elapsed":2676,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"be53eb21-36f1-4ffd-e217-801039b6b1ea"},"source":["!pip install tensorflow_addons"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u5Qgd95w-vfz"},"source":["# static"]},{"cell_type":"code","metadata":{"id":"nfPt8OFY-xIo"},"source":["TRAIN_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/train_images.csv'\r\n","TEST_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/test_images.csv'\r\n","SAMPLE_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/sample_submit.csv'\r\n","\r\n","TRAIN_IMAGE_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/train_images'\r\n","TEST_IMAGE_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/test_images'\r\n","\r\n","MODEL_PATH = '/content/drive/MyDrive/SANDBOX/DATASET/model.h5'\r\n","\r\n","TRAIN_TEST_SPLIT = 0.1\r\n","IMAGE_SIZE = 640\r\n","BATCH_SIZE = 1\r\n","EPOCHS = 100\r\n","\r\n","LABEL_NAMES = ['0 - best', '1 - good', '2 - processed', '3 - non-standard']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IbVRt8p0_Fd0"},"source":["# function"]},{"cell_type":"markdown","metadata":{"id":"fU8f8VFhBRNS"},"source":["## custom callback"]},{"cell_type":"code","metadata":{"id":"Sg9333CG_Grk"},"source":["from keras.callbacks import Callback\r\n","from sklearn.metrics import accuracy_score, cohen_kappa_score\r\n","import numpy as np\r\n","\r\n","class CustomCallback(Callback):\r\n","  \r\n","  def __init__(self, model, generator):\r\n","    self.model = model\r\n","    self.generator = generator\r\n","  \r\n","  def on_epoch_end(self, epoch, logs):\r\n","    acc = accuracy_score(np.argmax(self.model.predict(self.generator), axis=1), self.generator.classes)\r\n","    qwk = cohen_kappa_score(np.argmax(self.model.predict(self.generator), axis=1), self.generator.classes, weights='quadratic')\r\n","    print('Accuracy: {0:.3f}, QWK: {1:.3f}'.format(acc, qwk))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GsLsSFhu-n_t"},"source":["# load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Dn-im44-mKJ","executionInfo":{"status":"ok","timestamp":1615341222027,"user_tz":-540,"elapsed":4331,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"5d1038cf-e437-4dc1-c839-1b5eb82334b2"},"source":["import pandas as pd\r\n","# pd.set_option('display.max_colwidth', 100)\r\n","\r\n","from keras.utils import to_categorical\r\n","\r\n","df = pd.read_csv(TRAIN_PATH)\r\n","df_preds = pd.read_csv(TEST_PATH)\r\n","\r\n","df['id'] = TRAIN_IMAGE_PATH+'/'+df['id']\r\n","\r\n","df['class_num'] = df['class_num'].astype(str)\r\n","\r\n","print('df shape: {0}, df_preds shape: {1}'.format(df.shape, df_preds.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["df shape: (1102, 2), df_preds shape: (1651, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLtGxNaT_aFq","executionInfo":{"status":"ok","timestamp":1615341222359,"user_tz":-540,"elapsed":4658,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOUzTMS6Ybcs-p3RWSQ9sAPSGuYFVuT8ivT9ck=s64","userId":"10300123485870236269"}},"outputId":"3456c9fb-813c-4fa9-8632-f305367f44de"},"source":["from sklearn.model_selection import train_test_split\r\n","\r\n","TRAIN_VALIDATION_SPLIT = 0.2\r\n","\r\n","df_train, df_test = train_test_split(df, test_size=TRAIN_TEST_SPLIT, random_state=2021)\r\n","df_train, df_val = train_test_split(df_train, test_size=TRAIN_VALIDATION_SPLIT, random_state=2021)\r\n","\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","\r\n","train_datagen = ImageDataGenerator(featurewise_center=False,\r\n","                                   samplewise_center=False,\r\n","                                   featurewise_std_normalization=False,\r\n","                                   samplewise_std_normalization=False,\r\n","                                   zca_whitening=True,\r\n","                                   rotation_range=360,\r\n","                                   width_shift_range=1.0,\r\n","                                   height_shift_range=1.0,\r\n","                                   shear_range=0.2,\r\n","                                   zoom_range=0.2,\r\n","                                   channel_shift_range=0.0,\r\n","                                   fill_mode='nearest',\r\n","                                   cval=0.0,\r\n","                                   horizontal_flip=True,\r\n","                                   vertical_flip=True,\r\n","                                   rescale=1./255.,\r\n","                                   preprocessing_function=None,\r\n","                                   data_format=None,)\r\n","# train_datagen = ImageDataGenerator(rescale=1./255.,)\r\n","val_datagen = ImageDataGenerator(rescale=1./255.,)\r\n","test_datagen = ImageDataGenerator(rescale=1./255.,)\r\n","\r\n","train_generator = train_datagen.flow_from_dataframe(df_train, \r\n","                                                    directory=TRAIN_IMAGE_PATH, \r\n","                                                    x_col='id', \r\n","                                                    y_col='class_num', \r\n","                                                    target_size=(IMAGE_SIZE, IMAGE_SIZE), \r\n","                                                    batch_size=BATCH_SIZE, \r\n","                                                    class_mode='categorical')\r\n","val_generator = val_datagen.flow_from_dataframe(df_val, \r\n","                                                directory=TRAIN_IMAGE_PATH, \r\n","                                                x_col='id', \r\n","                                                y_col='class_num', \r\n","                                                target_size=(IMAGE_SIZE, IMAGE_SIZE), \r\n","                                                batch_size=BATCH_SIZE, \r\n","                                                class_mode='categorical', \r\n","                                                shuffle=False)\r\n","test_generator = test_datagen.flow_from_dataframe(df_test, \r\n","                                                  directory=TRAIN_IMAGE_PATH, \r\n","                                                  x_col='id', \r\n","                                                  y_col='class_num', \r\n","                                                  target_size=(IMAGE_SIZE, IMAGE_SIZE), \r\n","                                                  batch_size=BATCH_SIZE, \r\n","                                                  class_mode='categorical', \r\n","                                                  shuffle=False)\r\n","\r\n","for data_batch, labels_batch in train_generator:\r\n","  print('data batch shape: ', data_batch.shape)\r\n","  print('labels batch shape: ', labels_batch.shape)\r\n","  break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 792 validated image filenames belonging to 4 classes.\n","Found 199 validated image filenames belonging to 4 classes.\n","Found 111 validated image filenames belonging to 4 classes.\n","data batch shape:  (1, 640, 640, 3)\n","labels batch shape:  (1, 4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b-lxm7L_EHdN"},"source":["# create model"]},{"cell_type":"code","metadata":{"id":"vTmVMzcKDpUP"},"source":["from keras import models\r\n","from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB5, EfficientNetB7\r\n","from keras.layers import Flatten, BatchNormalization, Dense, GlobalAveragePooling2D, Dropout\r\n","\r\n","model = models.Sequential()\r\n","\r\n","# conv_base = VGG16(weights='imagenet', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False)\r\n","# conv_base = ResNet50(weights='imagenet', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False)\r\n","# conv_base = EfficientNetB5(weights='imagenet', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False)\r\n","conv_base = EfficientNetB7(weights='imagenet', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False)\r\n","\r\n","### freezing ###\r\n","# TARGET_LAYER = 'block5_conv2'        # VGG16\r\n","# TARGET_LAYER = 'conv5_block3_2_conv' # ResNet50\r\n","\r\n","# conv_base.trainable = True\r\n","# set_trainable = False\r\n","\r\n","# for layer in conv_base.layers:\r\n","#   if layer.name == TARGET_LAYER:\r\n","#     set_trainable = True\r\n","#   if set_trainable:\r\n","#     layer.trainable = True\r\n","#   else:\r\n","#     layer.trainable = False\r\n","\r\n","for layer in conv_base.layers:\r\n","  layer.trainable = False\r\n","\r\n","# model.add(Flatten())\r\n","# model.add(BatchNormalization())\r\n","# model.add(Dense(256, activation='relu'))\r\n","# model.add(BatchNormalization())\r\n","# model.add(Dense(4, activation='softmax'))\r\n","\r\n","model.add(conv_base)\r\n","\r\n","model.add(GlobalAveragePooling2D())\r\n","# model.add(BatchNormalization())\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(2048, activation='relu'))\r\n","# model.add(BatchNormalization())\r\n","model.add(Dropout(0.5))\r\n","model.add(Dense(4, activation='softmax'))\r\n","\r\n","# conv_base.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7l9KF0GvEHAa"},"source":["# fit\r\n","\r\n","[WightedKappaLoss](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/WeightedKappaLoss)\r\n","\r\n","[CohenKappa](https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/CohenKappa)\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wXuVaeYdD_BY","outputId":"58061e9a-a14c-44a1-a0ac-63a35cb9e2a8"},"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n","from keras.optimizers import Adam, SGD, Adagrad\r\n","from tensorflow_addons.losses import WeightedKappaLoss\r\n","from tensorflow_addons.metrics import CohenKappa\r\n","from tensorflow_addons.optimizers import RectifiedAdam\r\n","import time\r\n","\r\n","LEARNING_RATE_WARMUP = 1e-3\r\n","EPOCHS_WARMUP = 100\r\n","LEARNING_RATE = 1e-5\r\n","\r\n","print('### START WARMUP ###')\r\n","\r\n","# MONITOR_EARLYSTOPPING = 'val_cohen_kappa'\r\n","# MONITOR_MODELCHECKPOINT = 'val_cohen_kappa'\r\n","MONITOR_EARLYSTOPPING = 'val_loss'\r\n","MONITOR_MODELCHECKPOINT = 'val_loss'\r\n","\r\n","callbacks_list = [# EarlyStopping(monitor=MONITOR_EARLYSTOPPING, patience=5, mode='min',),\r\n","                  ReduceLROnPlateau(monitor='val_loss', mode='min', patience=3, factor=0.5, min_lr=1e-6, verbose=1),\r\n","                  CustomCallback(model, val_generator),\r\n","                  ModelCheckpoint(filepath=MODEL_PATH, monitor=MONITOR_MODELCHECKPOINT, save_best_only=True, mode='min',),]\r\n","\r\n","model.compile(optimizer=Adam(lr=LEARNING_RATE_WARMUP),\r\n","              # optimizer=RectifiedAdam(total_steps=10000, warmup_proportion=0.1, min_lr=1e-5),\r\n","              # optimizer=Adagrad(lr=LEARNING_RATE_WARMUP),\r\n","              # optimizer=SGD(lr=1e-3, momentum=0.9, decay=1e-5),\r\n","              loss='categorical_crossentropy',\r\n","              # metrics=['accuracy', CohenKappa(num_classes=4)]\r\n","              metrics=['accuracy',],)\r\n","\r\n","model.fit(train_generator,\r\n","          # epochs=EPOCHS_WARMUP,\r\n","          epochs=50,\r\n","          batch_size=BATCH_SIZE,\r\n","          callbacks=callbacks_list,\r\n","          validation_data=val_generator,)\r\n","\r\n","print('### END WARMUP ###')\r\n","\r\n","from tensorflow_addons.metrics import CohenKappa\r\n","from keras.models import load_model\r\n","\r\n","model = load_model(MODEL_PATH)\r\n","\r\n","for layer in model.layers:\r\n","    layer.trainable = True\r\n","\r\n","model.compile(# optimizer=Adam(1e-3),\r\n","              optimizer=Adam(LEARNING_RATE),\r\n","              # optimizer=RectifiedAdam(total_steps=10000, warmup_proportion=0.1, min_lr=1e-5),\r\n","              # optimizer=Adagrad(lr=LEARNING_RATE),\r\n","              # optimizer=SGD(lr=1e-3, momentum=0.9, decay=1e-5),\r\n","              # optimizer=SGD(lr=0.01, momentum=0.9, decay=0.001),\r\n","              # optimizer=SGD(lr=1e-5, momentum=0.9, decay=1e-6),\r\n","              loss='categorical_crossentropy',\r\n","              # loss=WeightedKappaLoss(num_classes=4),\r\n","              # metrics=['accuracy', CohenKappa(num_classes=4)]\r\n","              metrics=['accuracy',],)\r\n","\r\n","start = time.time()\r\n","\r\n","history = model.fit(train_generator, \r\n","                    # epochs=EPOCHS, \r\n","                    epochs=50,\r\n","                    callbacks=callbacks_list, \r\n","                    batch_size=BATCH_SIZE,\r\n","                    validation_data=val_generator)\r\n","\r\n","elapsed_time = time.time() - start\r\n","print('Elapsed time: {:.2f}[hours]'.format(elapsed_time / 3600))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["### START WARMUP ###\n","Epoch 1/50\n","792/792 [==============================] - 148s 164ms/step - loss: 2.2916 - accuracy: 0.2597 - val_loss: 1.3515 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 2/50\n","792/792 [==============================] - 128s 161ms/step - loss: 1.4211 - accuracy: 0.3381 - val_loss: 1.3677 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 3/50\n","792/792 [==============================] - 127s 160ms/step - loss: 1.3629 - accuracy: 0.3601 - val_loss: 1.3608 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 4/50\n","792/792 [==============================] - 128s 161ms/step - loss: 1.3727 - accuracy: 0.3807 - val_loss: 1.4002 - val_accuracy: 0.1709\n","\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Accuracy: 0.171, QWK: 0.000\n","Epoch 5/50\n","792/792 [==============================] - 127s 161ms/step - loss: 1.3802 - accuracy: 0.3449 - val_loss: 1.3450 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 6/50\n","792/792 [==============================] - 128s 162ms/step - loss: 1.3596 - accuracy: 0.3437 - val_loss: 1.3369 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 7/50\n","792/792 [==============================] - 128s 162ms/step - loss: 1.3622 - accuracy: 0.3620 - val_loss: 1.3443 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 8/50\n","792/792 [==============================] - 129s 162ms/step - loss: 1.3520 - accuracy: 0.3787 - val_loss: 1.3385 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 9/50\n","792/792 [==============================] - 130s 164ms/step - loss: 1.3722 - accuracy: 0.3822 - val_loss: 1.3379 - val_accuracy: 0.3970\n","\n","Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 10/50\n","792/792 [==============================] - 128s 162ms/step - loss: 1.3564 - accuracy: 0.3698 - val_loss: 1.3387 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 11/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3686 - accuracy: 0.3435 - val_loss: 1.3341 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 12/50\n","792/792 [==============================] - 131s 165ms/step - loss: 1.3629 - accuracy: 0.3688 - val_loss: 1.3402 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 13/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3513 - accuracy: 0.3806 - val_loss: 1.3387 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 14/50\n","792/792 [==============================] - 128s 161ms/step - loss: 1.3546 - accuracy: 0.3762 - val_loss: 1.3396 - val_accuracy: 0.3970\n","\n","Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 15/50\n","792/792 [==============================] - 127s 160ms/step - loss: 1.3532 - accuracy: 0.3746 - val_loss: 1.3326 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 16/50\n","792/792 [==============================] - 127s 161ms/step - loss: 1.3596 - accuracy: 0.3632 - val_loss: 1.3325 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 17/50\n","792/792 [==============================] - 127s 161ms/step - loss: 1.3474 - accuracy: 0.3827 - val_loss: 1.3363 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 18/50\n","792/792 [==============================] - 127s 160ms/step - loss: 1.3399 - accuracy: 0.3985 - val_loss: 1.3399 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 19/50\n","792/792 [==============================] - 127s 161ms/step - loss: 1.3500 - accuracy: 0.3681 - val_loss: 1.3357 - val_accuracy: 0.3970\n","\n","Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 20/50\n","792/792 [==============================] - 130s 164ms/step - loss: 1.3554 - accuracy: 0.3706 - val_loss: 1.3349 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 21/50\n","792/792 [==============================] - 129s 162ms/step - loss: 1.3560 - accuracy: 0.3671 - val_loss: 1.3344 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 22/50\n","792/792 [==============================] - 130s 164ms/step - loss: 1.3568 - accuracy: 0.3534 - val_loss: 1.3333 - val_accuracy: 0.3970\n","\n","Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 23/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3694 - accuracy: 0.3265 - val_loss: 1.3330 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 24/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3591 - accuracy: 0.3524 - val_loss: 1.3326 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 25/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3394 - accuracy: 0.3878 - val_loss: 1.3336 - val_accuracy: 0.3970\n","\n","Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 26/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3509 - accuracy: 0.3700 - val_loss: 1.3332 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 27/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3436 - accuracy: 0.3783 - val_loss: 1.3336 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 28/50\n","792/792 [==============================] - 129s 162ms/step - loss: 1.3368 - accuracy: 0.3821 - val_loss: 1.3333 - val_accuracy: 0.3970\n","\n","Epoch 00028: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 29/50\n","792/792 [==============================] - 128s 162ms/step - loss: 1.3560 - accuracy: 0.3590 - val_loss: 1.3332 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 30/50\n","792/792 [==============================] - 129s 162ms/step - loss: 1.3531 - accuracy: 0.3703 - val_loss: 1.3332 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 31/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3441 - accuracy: 0.3862 - val_loss: 1.3334 - val_accuracy: 0.3970\n","\n","Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 32/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3557 - accuracy: 0.3581 - val_loss: 1.3334 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 33/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3463 - accuracy: 0.3708 - val_loss: 1.3335 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 34/50\n","792/792 [==============================] - 129s 162ms/step - loss: 1.3666 - accuracy: 0.3465 - val_loss: 1.3335 - val_accuracy: 0.3970\n","\n","Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 35/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3606 - accuracy: 0.3610 - val_loss: 1.3336 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 36/50\n","792/792 [==============================] - 129s 162ms/step - loss: 1.3625 - accuracy: 0.3526 - val_loss: 1.3337 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 37/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3592 - accuracy: 0.3591 - val_loss: 1.3337 - val_accuracy: 0.3970\n","\n","Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-06.\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 38/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3323 - accuracy: 0.4099 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 39/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3493 - accuracy: 0.3784 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 40/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3471 - accuracy: 0.3755 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 41/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3440 - accuracy: 0.3639 - val_loss: 1.3337 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 42/50\n","792/792 [==============================] - 128s 162ms/step - loss: 1.3440 - accuracy: 0.3772 - val_loss: 1.3337 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 43/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3571 - accuracy: 0.3613 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 44/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3427 - accuracy: 0.3843 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 45/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3502 - accuracy: 0.3658 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 46/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3503 - accuracy: 0.3685 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 47/50\n","792/792 [==============================] - 130s 164ms/step - loss: 1.3423 - accuracy: 0.3845 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 48/50\n","792/792 [==============================] - 130s 163ms/step - loss: 1.3635 - accuracy: 0.3520 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 49/50\n","792/792 [==============================] - 130s 164ms/step - loss: 1.3643 - accuracy: 0.3448 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 50/50\n","792/792 [==============================] - 129s 163ms/step - loss: 1.3410 - accuracy: 0.3780 - val_loss: 1.3338 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","### END WARMUP ###\n","Epoch 1/50\n","792/792 [==============================] - 576s 694ms/step - loss: 1.4428 - accuracy: 0.3765 - val_loss: 1.3243 - val_accuracy: 0.3970\n","Accuracy: 0.397, QWK: 0.000\n","Epoch 2/50\n","223/792 [=======>......................] - ETA: 6:17 - loss: 0.8909 - accuracy: 0.6464"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jI83cydZFNFq"},"source":["# evaluate"]},{"cell_type":"code","metadata":{"id":"CTp_xN97Ed-6"},"source":["import matplotlib.pyplot as plt\r\n","\r\n","acc = history.history['accuracy']\r\n","val_acc = history.history['val_accuracy']\r\n","loss = history.history['loss']\r\n","val_loss = history.history['val_loss']\r\n","# cohen_kappa = history.history['cohen_kappa']\r\n","# val_cohen_kappa = history.history['val_cohen_kappa']\r\n","epochs = range(1, len(acc) + 1)\r\n","\r\n","fig = plt.figure(0)\r\n","\r\n","plt.plot(epochs, acc, 'b', label='Training acc')\r\n","plt.plot(epochs, val_acc, 'b', color='orange', label='Validation acc')\r\n","plt.title('Training and validation accuracy')\r\n","plt.legend()\r\n","\r\n","fig.savefig('acc.jpg')\r\n","\r\n","plt.show()\r\n","\r\n","fig = plt.figure(1)\r\n","\r\n","plt.plot(epochs, loss, 'b', label='Training loss')\r\n","plt.plot(epochs, val_loss, 'b', color='orange', label='Validation loss')\r\n","plt.title('Training and validation loss')\r\n","plt.legend()\r\n","\r\n","fig.savefig('loss.jpg')\r\n","\r\n","plt.show()\r\n","\r\n","# fig = plt.figure(2)\r\n","\r\n","# plt.plot(epochs, cohen_kappa, 'b', label='Training cohen kappa')\r\n","# plt.plot(epochs, val_cohen_kappa, 'b', color='orange', label='Validation cohen kappa')\r\n","# plt.title('Training and validation cohen kappa')\r\n","# plt.legend()\r\n","\r\n","# fig.savefig('cohen_kappa.jpg')\r\n","\r\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiYo7TNxOsDB"},"source":["from tensorflow_addons.metrics import CohenKappa\r\n","from keras.models import load_model\r\n","\r\n","clf = load_model(MODEL_PATH)\r\n","# clf = load_model(MODEL_PATH, custom_objects={'cohen_kappa': CohenKappa(num_classes=4)})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7njpUKesFPJU"},"source":["import numpy as np\r\n","from sklearn.metrics import confusion_matrix \r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","\r\n","predicted = np.argmax(clf.predict(test_generator), axis=1)\r\n","test_labels = test_generator.classes\r\n","\r\n","cf_matrix = confusion_matrix(test_labels, predicted)\r\n","\r\n","fig = plt.figure(figsize=(16, 8))\r\n","\r\n","sns.heatmap(cf_matrix, annot=True, cmap='Greens', xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES)\r\n","\r\n","plt.xlabel('Predicted')\r\n","plt.ylabel('Actual')\r\n","\r\n","fig.savefig('cf_matrix.jpg')\r\n","\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5epcgURJPNEo"},"source":["from sklearn.metrics import cohen_kappa_score, accuracy_score\r\n","\r\n","print('Test cohen kappa score: %.3f' % cohen_kappa_score(np.argmax(clf.predict(test_generator), axis=1), test_generator.classes, weights='quadratic'))\r\n","print('Test accuracy score : %.3f' % accuracy_score(np.argmax(clf.predict(test_generator), axis=1), test_generator.classes))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ObBSVBXIkJXX"},"source":["# result\r\n","\r\n","|model|optimizer warmup|optimizer|test cohen kappa|test accuracy|Public Leaderbord|\r\n","|:--:|:--:|:--:|:--:|:--:|:--:|\r\n","|ResNet50|Adam(1e-3)|Adam(1e-4)|1.000|1.000|0.8934451|\r\n","|ResNet50|SGD(lr=0.2, momentum=0.9, decay=0.01)|SGD(lr=0.01, momentum=0.9, decay=0.001)|0.000|0.279|FFFF|\r\n","|EfficientNetB5|Adam(1e-3)|Adam(1e-4)|1.000|1.000|0.9471134|\r\n","|EfficientNetB7|Adam(1e-3)|Adam(1e-4)|1.000|1.000|FFFF|\r\n","|FFFF|FFFF|FFFF|FFFF|FFFF|FFFF|"]},{"cell_type":"markdown","metadata":{"id":"Y83E6LyPOtzh"},"source":["# submit"]},{"cell_type":"code","metadata":{"id":"bhzsoSgcIzVZ"},"source":["import numpy as np\r\n","from PIL import Image\r\n","\r\n","preds = []\r\n","\r\n","for image_id in df_preds['id']:\r\n","    image = Image.open(TEST_IMAGE_PATH+'/'+image_id)\r\n","    # image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\r\n","    image = np.expand_dims(image, axis=0)\r\n","    image = image / 255.\r\n","    preds.append(np.argmax(clf.predict(image)))\r\n","\r\n","df_preds['label'] = preds\r\n","\r\n","df_preds.to_csv('/content/drive/MyDrive/SANDBOX/DATASET/submission.csv', index=False, header=False)\r\n","\r\n","df_preds.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fXzuBXdibyHg"},"source":["# Colab\r\n","\r\n","```javascript\r\n","function ClickConnect(){ \r\n","console.log(\"Working\"); \r\n","document.querySelector(\"#comments > span\").click()\r\n","}\r\n","setInterval(ClickConnect,500000)\r\n","```"]}]}